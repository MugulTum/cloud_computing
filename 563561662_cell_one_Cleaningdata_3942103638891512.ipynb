from pyspark.sql import SparkSession
from pyspark.sql.functions import col, round
from pyspark.sql.types import IntegerType, FloatType, TimestampType

# Initialize Spark session
spark = SparkSession.builder \
    .appName("Q1") \
    .getOrCreate()

# Load the dataset
df = spark.read.option("header", True).csv("yellow_tripdata_2019-01_short.csv")

def clean_data(df):
    # Cast columns to specified data types
    df = df.withColumn("passenger_count", col("passenger_count").cast(IntegerType()))
    df = df.withColumn("total_amount", col("total_amount").cast(FloatType()))
    df = df.withColumn("tip_amount", col("tip_amount").cast(FloatType()))
    df = df.withColumn("trip_distance", col("trip_distance").cast(FloatType()))
    df = df.withColumn("fare_amount", col("fare_amount").cast(FloatType()))
    df = df.withColumn("tpep_pickup_datetime", col("tpep_pickup_datetime").cast(TimestampType()))
    df = df.withColumn("tpep_dropoff_datetime", col("tpep_dropoff_datetime").cast(TimestampType()))
    
    # Round trip distances up to the closest mile
    df = df.withColumn("trip_distance", round(col("trip_distance")).cast(IntegerType()))
    
    return df

# Clean the data
df_cleaned = clean_data(df)
df_cleaned.show(5)
