from pyspark.sql.functions import sum, avg, col, expr
from pyspark.sql.window import Window

def common_pair(df):
    # Filter out trips with the same pick-up and drop-off location
    df = df.filter(df['PULocationID'] != df['DOLocationID'])
    
    # Group by pick-up and drop-off location, compute total passengers and average fare per passenger
    df = df.groupBy("PULocationID", "DOLocationID") \
           .agg(sum("passenger_count").alias("total_passenger_count"),
                (sum("total_amount") / sum("passenger_count")).alias("per_person_rate"))
    
    # Sort by total passengers and per-person rate
    window = Window.orderBy(col("total_passenger_count").desc(), col("per_person_rate").desc())
    df = df.withColumn("rank", expr("row_number() over (partition by null order by total_passenger_count desc, per_person_rate desc)")) \
           .filter(col("rank") <= 10) \
           .drop("rank") \
           .orderBy(col("total_passenger_count").desc(), col("per_person_rate").desc())
    
    return df

# Find common trip pairs
common_trip_pairs = common_pair(df_cleaned)
common_trip_pairs.show()
